{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Information:\n",
    "\n",
    "### Team Member 1:\n",
    "* UNI:  asp2197\n",
    "* Name: Abhay Pawar\n",
    "\n",
    "### Team Member 2 [optional]:\n",
    "* UNI:  vb2424\n",
    "* Name: Vijay Balaji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step0 - Import Libraries, Load Data [0 points]\n",
    "\n",
    "This is the basic step where you can load the data and create train and test sets for internal validation as per your convinience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import f_regression,RFE,RFECV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "holdout = pd.read_csv(\"holdout.csv\")\n",
    "data.head()\n",
    "\n",
    "sub=data.subscribed.copy().as_matrix()\n",
    "data.drop(['subscribed'],axis=1,inplace=True)\n",
    "hold_ids=holdout.ID.copy()\n",
    "holdout.drop(['ID'],axis=1,inplace=True)\n",
    "y=np.zeros(len(sub))\n",
    "for i in range(len(sub)):\n",
    "    if sub[i]=='no':\n",
    "        y[i]=0\n",
    "    elif sub[i]=='yes':\n",
    "        y[i]=1\n",
    "        \n",
    "data.drop(['duration'],axis=1,inplace=True)\n",
    "holdout.drop(['duration'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1 - Exploration and Preparation [10 points]\n",
    "\n",
    "In this step, we expect you to look into the data and try to understand it before modeling. This understanding may lead to some basic data preparation steps which are common across the two model sets required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did initial exploration of the data in excel using pivot tables and filters as it is much more convenient. We realized that the train and holdout data don't have the same categories for some categorical variables. We compared the categories in these variables in train and holdout data and did grouping so that both datasets have same categories. The grouping was done by looking at every categorical feature individually and grouping catgories which have very similar event rates. Following code does the grouping.\n",
    "We also checked if there are any outliers. There are no outliers in the continuous features. prev_days had a value 999 which means that customer wasn't contacted. We have converted this feature into a binary and tells if the customer was contacted or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loangroup(dataset):\n",
    "    temp = dataset['loan'].copy()\n",
    "    temp[dataset['loan']=='unknown'] = 'no'\n",
    "    dataset['loan'] = temp\n",
    "def housinggroup(dataset):\n",
    "    temp = dataset['housing'].copy()\n",
    "    temp[dataset['housing']=='unknown'] = 'yes'\n",
    "    dataset['housing'] = temp\n",
    "def credit_defaultgroup(dataset):\n",
    "    temp = dataset['credit_default']\n",
    "    temp[dataset['credit_default']=='unknown'] = 'yes'\n",
    "    dataset['credit_default'] = temp\n",
    "def educationgroup(dataset):\n",
    "    temp = dataset['education'].copy()\n",
    "    temp[dataset['education']=='unknown'] = 'illiterate'\n",
    "    dataset['education'] = temp\n",
    "def jobgroup(dataset):\n",
    "    temp = dataset['job'].copy()\n",
    "    temp[dataset['job']=='unknown'] = 'technician'\n",
    "    temp[dataset['job']=='housemaid'] = 'technician'\n",
    "    temp[dataset['job']=='entrepreneur'] = 'services'\n",
    "    dataset['job'] = temp\n",
    "def maritalgroup(dataset):\n",
    "    temp = dataset['marital_status'].copy()\n",
    "    temp[dataset['marital_status']=='unknown'] = 'single'\n",
    "    dataset['marital_status'] = temp\n",
    "\n",
    "def campaigngroup(dataset):\n",
    "    temp = dataset['campaign'].copy()\n",
    "    temp[dataset['campaign']<5] = 1\n",
    "    temp[(dataset['campaign']<8) & (dataset['campaign']>=5)] = 2\n",
    "    temp[dataset['campaign']>=8] = 3\n",
    "    dataset['campaign'] = temp\n",
    "    dataset['campaign'] = dataset['campaign'].astype('category')\n",
    "    \n",
    "def monthgroup(dataset):\n",
    "    temp = dataset['month'].copy()\n",
    "    temp[dataset['month']=='nov'] = 'jun'\n",
    "    temp[dataset['month']=='aug'] = 'jun'\n",
    "    dataset['month'] = temp\n",
    "\n",
    "def prev_daysgroup(dataset):\n",
    "    temp = dataset['prev_days'].copy()\n",
    "    temp.iloc[np.where(dataset['prev_days']!=999)] = 0\n",
    "    temp.iloc[np.where(dataset['prev_days']==999)] = 1\n",
    "    dataset['prev_days_binary'] = temp    \n",
    "\n",
    "def agegroup(dataset):\n",
    "    temp=dataset['age'].copy()\n",
    "    temp[dataset['age']<=20] = 20\n",
    "    temp[(dataset['age']>20) & (dataset['age']<=26)] = 26\n",
    "    temp[(dataset['age']>26) & (dataset['age']<=30)] = 30\n",
    "    temp[(dataset['age']>30) & (dataset['age']<=38)] = 38\n",
    "    temp[(dataset['age']>38) & (dataset['age']<=51)] = 51\n",
    "    temp[(dataset['age']>51) & (dataset['age']<=61)] = 61\n",
    "    temp[dataset['age']>61] = 62\n",
    "    dataset['age_group']=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijay\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "loangroup(data)\n",
    "loangroup(holdout)\n",
    "housinggroup(data)\n",
    "housinggroup(holdout)\n",
    "credit_defaultgroup(data)\n",
    "credit_defaultgroup(holdout)\n",
    "educationgroup(data)\n",
    "educationgroup(holdout)\n",
    "jobgroup(data)\n",
    "jobgroup(holdout)\n",
    "maritalgroup(data)\n",
    "maritalgroup(holdout)\n",
    "campaigngroup(data)\n",
    "campaigngroup(holdout)\n",
    "monthgroup(data)\n",
    "monthgroup(holdout)\n",
    "prev_daysgroup(data)\n",
    "prev_daysgroup(holdout)\n",
    "agegroup(data)\n",
    "agegroup(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat = ['age_group','job','marital_status','education','prev_outcomes','month','contact','campaign','day_of_week']\n",
    "for c in cat:\n",
    "    data[c] = data[c].astype('category')\n",
    "    holdout[c] = holdout[c].astype('category')\n",
    "X = pd.get_dummies(data)\n",
    "X_holdout = pd.get_dummies(holdout)\n",
    "X=X.drop(X.columns[[29, 31,33,35]],axis=1)\n",
    "X_holdout=X_holdout.drop(X_holdout.columns[[29, 31,33,35]],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdout = pd.get_dummies(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(data.columns[[29,31,33,35]],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdout.drop(data.columns[[29,31,33,35]],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train,data_test,y_train,y_test = train_test_split(data,y,random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 - ModelSet1 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set1:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. Any classification algorithm covered in class apart from tree-based models can be tested here.\n",
    "\n",
    "Feature Engineering/Selection: \n",
    "\n",
    "We tried to create a new feature using prev_days and prev_outcome. Reason being that customers with prev_days==999 have prev_outcome as unknown and hence, there is high correlation. But, this feature did not add any improvement in logistic regression and hence, we decided to not use it. We converted prev_days into a binary variable for logistic regression as 999 value is too high. We used prev_days as it is for tree based models as 999 value wouldn't affect the results.\n",
    "\n",
    "We tried using the F scores from f_classif and RFECV to select the features. RFECV gave better results and hence, we have used it for all the models.\n",
    "\n",
    "Validation:\n",
    "Since, cross-val-score computes scores on random splits on data, we initially created a single 20% test data to check the performance of models. But, improvement in AUC on this test data didn't necessarily convert into improvement on the holdout on Leaderboard. So, we shifted to using cross_val_score. \n",
    "\n",
    "Classifiers used:\n",
    "We used logistic regression, KNN, Naive bayes in this stage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#F scores\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=11)\n",
    "F,p=feature_selection.f_classif(X_train.as_matrix(),y_train)\n",
    "Fscore=pd.DataFrame(X_train.columns)\n",
    "Fscore['F_value']=F\n",
    "Fscore['p_value']=p\n",
    "#Fscore.to_csv('Dummies_fscore.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logistic regression we first selected the features using RFECV and then used gridsearch to find optimal C with l2 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#selector = RFECV(LogisticRegression(penalty='l2',C=0.005), step=1, cv=2,scoring='roc_auc')\n",
    "#selector = selector.fit(data_train, y_train)\n",
    "#print selector.support_ \n",
    "#print selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#klr=[]\n",
    "#for i in range(len(selector.support_)):\n",
    "    #if selector.support_[i]==False:\n",
    "        #klr.append(i)\n",
    "#klr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "klr = [0,1,3,4,5,7,8,9,16,17,18,19,21,22,25,27,29,30,35,40,53,56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grid searched for C\n",
    "\n",
    "lr=make_pipeline(StandardScaler(),LogisticRegression(penalty='l2',C=0.005))\n",
    "#param_grid={'logisticregression__C':np.arange(0.001,0.02,0.002)}\n",
    "#gd=GridSearchCV(lr,param_grid=param_grid,scoring='roc_auc',cv=3)\n",
    "#gd.fit(data.drop(data.columns[[k]],axis=1),y)\n",
    "#gd.best_params_ \n",
    "#lr=LogisticRegression()\n",
    "#lr.fit(data.drop(data.columns[[k]],axis=1),y)\n",
    "#plr=make_pipeline(StandardScaler(),lr)\n",
    "#plr.fit(data_train.drop(data_train.columns[[k]],axis=1),y_train)\n",
    "lr.fit(data_train,y_train)\n",
    "y_predict_lr = lr.predict_proba(data_test)\n",
    "#print roc_auc_score(y_test,y_predict_lr[:,1])\n",
    "#scores=cross_val_score(lr,data.drop(data.columns[[k]],axis=1),y,cv=5,scoring='roc_auc')\n",
    "#scores\n",
    "#scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78848358878087521"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(data_train.drop(data_train.columns[[klr]],axis=1),y_train)\n",
    "y_pred_lr_train=lr.predict_proba(data_test.drop(data_test.columns[[klr]],axis=1))[:,1]\n",
    "roc_auc_score(y_test,y_pred_lr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr.fit(data,y)\n",
    "y_res_lr=lr.predict_proba(holdout)\n",
    "\n",
    "output=pd.DataFrame(hold_ids)\n",
    "#output['ID']=hold_ids\n",
    "output['subscribed']=y_res_lr[:,1]\n",
    "#output.to_csv(\"lrv3removing4cols.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adaboost:\n",
    "#Tried adaboost with log loss but couldn't get good results.\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier(loss='log', penalty='l2', alpha=1, l1_ratio=0.5, fit_intercept=True, n_iter=5, shuffle=True, verbose=0, \n",
    "              epsilon=0.1, n_jobs=1, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, class_weight=None, \n",
    "              warm_start=False, average=False)\n",
    "abc=AdaBoostClassifier(base_estimator=SVC(), n_estimators=50, learning_rate=1.0, algorithm='SAMME', random_state=None)\n",
    "\n",
    "#abc.fit(data_train,y_train)\n",
    "#y_predict_abc_train=abc.predict_proba(data_test)\n",
    "#print roc_auc_score(y_test,y_predict[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN, we tried with scaling the features. But, it gave worst results as compared to without scaling. Probable reason could be that high predictive features which should have higher weight get scaled down and hence, contribute as much as non-predictive features. Hence, worsening the performance. We also tried dropping low F score features, but it didn't give much improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763773088328\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "knn=KNeighborsClassifier(n_neighbors=40, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', \n",
    "                     metric_params=None, n_jobs=1)\n",
    "#grid searched for n-neighbors\n",
    "knn_pipe=make_pipeline(knn)\n",
    "knn_pipe.fit(data_train,y_train)\n",
    "y_predict_knn_train=knn.predict_proba(data_test)[:,1]\n",
    "#y_predict_knn_train=knn.predict_proba(data_train)[:,1]\n",
    "\n",
    "#print roc_auc_score(y_test,y_predict_knn)\n",
    "#print roc_auc_score(y_test,y_predict_knn_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_pipe.fit(data,y)\n",
    "y_predict_knn=knn_pipe.predict_proba(holdout)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes: We used the gaussian assumption which won't be true for all the features. Still NB performs decent. We tried dropping features which are highly correlation. But, this did not much improvement. Only dropping one feature gave better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76426767525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "nbg=GaussianNB()\n",
    "nbg.fit(data_train,y_train)\n",
    "y_predict_nbg_train=nbg.predict_proba(data_test)[:,1]\n",
    "#y_predict_nbg_train=nbg.predict_proba(data_train)[:,1]\n",
    "roc_auc_score(y_test,y_predict_nbg_train)\n",
    "#print roc_auc_score(y_train,y_predict_nbg_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembles: We tried three different strategies to create ensemble model. \n",
    "1. Poor man's stacking: Building a model over the probabilities given by individual models\n",
    "2. Weighted averaging of probabilities from different model\n",
    "3. Weigthed average of rank of each customer from different models. Since, AUC depends only on how the customers are ranked by the probabilites, averaging the rank from probabilites from different models makes sense.\n",
    "2 and 3 gave improvement. 1 did not give much improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889310096503\n"
     ]
    }
   ],
   "source": [
    "#1. Poor man's stacking. Used GBC and logistic. GBC gave good results.\n",
    "#There is no validation sample here. We had used it originally. But, removed to make the code run faster on Travis.\n",
    "#X_train_ens=pd.DataFrame()\n",
    "X_train_ens=pd.DataFrame(y_pred_lr_train)\n",
    "X_train_ens.columns=['y_pred_lr_train']\n",
    "X_train_ens['y_predict_knn_train']=y_predict_knn_train\n",
    "X_train_ens['y_predict_nbg_train']=y_predict_nbg_train\n",
    "#X_train_ens['y_pred_train_gbc']=y_pred_train_gbc\n",
    "#X_test_ens=pd.DataFrame(y_predict_plr)\n",
    "#X_test_ens.columns=['y_predict_plr']\n",
    "#X_test_ens['y_predict_knn_train']=y_predict_knn\n",
    "#X_test_ens['y_predict_nbg_train']=y_predict_nbg\n",
    "#X_test_ens['y_pred_train_gbc']=y_predict_gbc\n",
    "gbc1=GradientBoostingClassifier(loss='exponential', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', \n",
    "                           min_samples_split=2, min_samples_leaf=2, min_weight_fraction_leaf=0.0, max_depth=10, \n",
    "                           min_impurity_split=1e-07, init=None, random_state=11, max_features=None, verbose=0, \n",
    "                           max_leaf_nodes=20, warm_start=False, presort='auto')\n",
    "gbc1.fit(X_train_ens,y_test)\n",
    "y_predict_ens=gbc1.predict_proba(X_train_ens)[:,1]\n",
    "#y_predict_ens_train=gbc1.predict_proba(X_train_ens)[:,1]\n",
    "\n",
    "roc_auc_score(y_test,y_predict_ens)\n",
    "#print roc_auc_score(y_train,y_predict_ens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787174929295\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(X_train_ens,y_test)\n",
    "y_predict_ens=lr.predict_proba(X_train_ens)[:,1]\n",
    "#y_predict_ens_train=gbc1.predict_proba(X_train_ens)[:,1]\n",
    "\n",
    "roc_auc_score(y_test,y_predict_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78956921672003544"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weighted average\n",
    "#We tried the Voting classifier as well. But, it doesn't allow to pass different features for different models. \n",
    "#So we wrote a function to do weighted averaging.\n",
    "def weightedprobs(w1,w2,w3):\n",
    "    y_predict_ensemble =((w1/(w1+w2+w3) * y_pred_lr_train)  + (w2/(w1+w2+w3) * y_predict_knn_train) + \n",
    "                         (w3/(w1+w2+w3) * y_predict_nbg_train))\n",
    "    return y_predict_ensemble\n",
    "\n",
    "#Following code finds the weights which maximise AUC. We use these weights for the ensemble.\n",
    "maxi=0\n",
    "maxj=0\n",
    "maxk=0\n",
    "maxl=0\n",
    "max=0\n",
    "for i in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "    for j in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "        for k in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "                if i + j + k!=0:\n",
    "                    y_predict_ensemble = weightedprobs(i,j,k)\n",
    "                    auc = roc_auc_score(y_test,y_predict_ensemble)\n",
    "                    if auc>max:\n",
    "                        maxi = i\n",
    "                        maxj = j\n",
    "                        maxk = k\n",
    "                        max = auc\n",
    "max\n",
    "#We got AUC of 0.7901 using ensemble of these three models which is an improvement of 0.03 over logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Program Files\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "G:\\Program Files\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:10: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.790109953216796"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weighted average of rank\n",
    "#Folowing function calculates the rank of each observation and assigns equally spaced probabilities to all the customers.\n",
    "def rank_pred(y):\n",
    "    y_pred=pd.DataFrame(y)\n",
    "    y_pred.columns=['y_pred']\n",
    "    y_pred_sorted=y_pred.sort(columns='y_pred').reset_index()\n",
    "    y_pred_sorted['rank']=pd.Series(np.zeros(len(y_pred)))\n",
    "    for i in range(len(y_pred_sorted)):\n",
    "        y_pred_sorted.set_value(i, 'rank', (i+0.0)/len(y_pred_sorted), takeable=False)\n",
    "    y_pred_fin=y_pred_sorted.sort(columns='index').reset_index(drop=True)\n",
    "    y_pred_rank=y_pred_fin['rank']\n",
    "    return y_pred_rank\n",
    "\n",
    "lr_rank=rank_pred(y_pred_lr_train)\n",
    "knn_rank=rank_pred(y_predict_knn_train)\n",
    "nbg_rank=rank_pred(y_predict_nbg_train)\n",
    "\n",
    "def weightedprobs_rank(w1,w2,w3):\n",
    "    y_predict_ensemble =((w1/(w1+w2+w3) * lr_rank)  + (w2/(w1+w2+w3) * knn_rank) + \n",
    "                         (w3/(w1+w2+w3) * nbg_rank))\n",
    "    return y_predict_ensemble\n",
    "\n",
    "#Following code finds the weights which maximise AUC. We use these weights for the ensemble.\n",
    "maxi=0\n",
    "maxj=0\n",
    "maxk=0\n",
    "maxl=0\n",
    "max=0\n",
    "for i in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "    for j in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "        for k in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "                if i + j + k!=0:\n",
    "                    y_predict_ensemble = weightedprobs(i,j,k)\n",
    "                    auc = roc_auc_score(y_test,y_predict_ensemble)\n",
    "                    if auc>max:\n",
    "                        maxi = i\n",
    "                        maxj = j\n",
    "                        maxk = k\n",
    "                        max = auc\n",
    "max\n",
    "#This method gave results close to 79.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3 - ModelSet2 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set2:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. We encourage you to try decition tree, random forest and gradient boosted tree methods here and pick the one which you think works best.\n",
    "\n",
    "Models used:\n",
    "\n",
    "We used random forest and gradient boosted trees in this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=10, min_samples_split=10, min_samples_leaf=10, \n",
    "                       min_weight_fraction_leaf=0.0,max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, \n",
    "                       bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, \n",
    "                       class_weight=None)\n",
    "#cross_val_score()\n",
    "#param_grid={'min_samples_split':np.linspace(1,1000,20)}\n",
    "#scores=cross_val_score(rf,data,y,cv=5,scoring='roc_auc')\n",
    "#print scores\n",
    "#print scores.mean()\n",
    "# try on whole data first\n",
    "rf.fit(data_train,y_train)\n",
    "y_predict_rf = rf.predict_proba(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True False  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 6 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 5 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#selector = RFECV(rf, step=1, cv=2,scoring='roc_auc')\n",
    "#selector = selector.fit(data_train, y_train)\n",
    "#print selector.support_ \n",
    "#print selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#k=[]\n",
    "#for i in range(len(selector.support_)):\n",
    "    #if selector.support_[i]==False:\n",
    "        #k.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = [13,17,22,33,51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80153043  0.79184887  0.7985749   0.80705359  0.79518305]\n",
      "0.798838166963\n"
     ]
    }
   ],
   "source": [
    "scores=cross_val_score(rf,data.drop(data.columns[[k]],axis=1),y,cv=5,scoring='roc_auc')\n",
    "#print scores\n",
    "#print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf.fit(data_train.drop(data_train.columns[[k]],axis=1),y_train)\n",
    "y_res_rf_train=rf.predict_proba(data_test.drop(data_test.columns[[k]],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf.fit(data,y)\n",
    "y_res_rf=rf.predict_proba(holdout)\n",
    "\n",
    "#output=pd.DataFrame(hold_ids)\n",
    "#output['ID']=hold_ids\n",
    "#output['subscribed']=y_pred[:,1]\n",
    "#output.to_csv(\"rf.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc2=GradientBoostingClassifier(min_samples_leaf=20,min_samples_split=2,max_depth=3)\n",
    "#param_grid={'max_leaf_nodes':[None,5,10,15,25,50]}\n",
    "#gd=GridSearchCV(gbc2,param_grid=param_grid,scoring='roc_auc',cv=3)\n",
    "#gd.fit(data_train,y_train)\n",
    "#gd.best_params_ \n",
    "#scores=cross_val_score(gbc2,data.drop(data.columns[[k]],axis=1),y,cv=5,scoring='roc_auc')\n",
    "#scores\n",
    "#scores.mean()\n",
    "gbc2.fit(data_train,y_train)\n",
    "y_predict_gbc2 = gbc2.predict_proba(data_test)\n",
    "#roc_auc_score(y_test,y_predict_gbc2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False False]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "#selector = RFECV(gbc2, step=1, cv=2,scoring='roc_auc')\n",
    "#selector = selector.fit(data_train, y_train)\n",
    "#print selector.support_ \n",
    "#print selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False False]\n"
     ]
    }
   ],
   "source": [
    "#print selector.support_\n",
    "#kgbc=[]\n",
    "#for i in range(len(selector.support_)):\n",
    "    #if selector.support_[i]==False:\n",
    "        #kgbc.append(i)\n",
    "#kgbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kgbc = [30,56,57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc2.fit(data_train.drop(data_train.columns[[kgbc]],axis=1),y_train)\n",
    "y_res_gbc_train=gbc2.predict_proba(data_test.drop(data_test.columns[[kgbc]],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc2.fit(data,y)\n",
    "y_res_gbc=gbc2.predict_proba(holdout)\n",
    "\n",
    "output=pd.DataFrame(hold_ids)\n",
    "#output['ID']=hold_ids\n",
    "#output['subscribed']=y_pred[:,1]\n",
    "#output.to_csv(\"gbcdefault.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried using gbc and rf for ensembles and some of our submissions have these ensembles, but we aren't showing it here. We shall directly use ensemble on all models used before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4 - Ensemble [20 points + 10 Bonus points]\n",
    "\n",
    "In this step, we expect you to use the models created before and create new predictions. You should definitely try poor man's stacking but we encourage you to think of different ensemble techniques as well. We will judge your creativity and improvement in model performance using ensemble models and you can potentially earn 10 bonus points here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "#assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightedprobs(w1,w2,w3):\n",
    "    y_predict_ensemble =((w1/(w1+w2+w3) * y_predict_lr[:,1])  + (w2/(w1+w2+w3) * y_predict_gbc2[:,1]) + (w3/(w1+w2+w3) * y_predict_rf[:,1]))\n",
    "    return y_predict_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxi=0\n",
    "maxj=0\n",
    "maxk=0\n",
    "maxl=0\n",
    "max=0\n",
    "for i in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "    for j in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "        for k in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "                if i + j + k!=0:\n",
    "                    y_predict_ensemble = weightedprobs(i,j,k)\n",
    "                    auc = roc_auc_score(y_test,y_predict_ensemble)\n",
    "                    if auc>max:\n",
    "                        maxi = i\n",
    "                        maxj = j\n",
    "                        maxk = k\n",
    "                        max = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79473247863133711"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', lr), ('rf', rf), ('gbc', gbc2)], voting='soft',weights=[maxi,maxk,maxj])\n",
    "eclf.fit(data_train,y_train)\n",
    "y_predict_ensemble = eclf.predict_proba(data_test)\n",
    "roc_auc_score(y_test,y_predict_ensemble[:,1])\n",
    "# gives an improvement of 0.1 over the maximum score of individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eclf.fit(data,y)\n",
    "y_pred_ensemble_fulldata=eclf.predict_proba(holdout)\n",
    "\n",
    "#output=pd.DataFrame(hold_ids)\n",
    "#output['ID']=hold_ids\n",
    "#output['subscribed']=y_pred[:,1]\n",
    "#output.to_csv(\"ensemblefulldata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_pred(y):\n",
    "    y_pred=pd.DataFrame(y)\n",
    "    y_pred.columns=['y_pred']\n",
    "    y_pred_sorted=y_pred.sort(columns='y_pred').reset_index()\n",
    "    y_pred_sorted['rank']=pd.Series(np.zeros(len(y_pred)))\n",
    "    for i in range(len(y_pred_sorted)):\n",
    "        y_pred_sorted.set_value(i, 'rank', (i+0.0)/len(y_pred_sorted), takeable=False)\n",
    "    y_pred_fin=y_pred_sorted.sort(columns='index').reset_index(drop=True)\n",
    "    y_pred_rank=y_pred_fin['rank']\n",
    "    return y_pred_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijay\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "C:\\Users\\vijay\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:8: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr_rank = rank_pred(y_predict_lr[:,1])\n",
    "y_pred_gbc_rank = rank_pred(y_predict_gbc2[:,1])\n",
    "y_pred_rf_rank = rank_pred(y_predict_rf[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_res_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-23ed9f73c4d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_res_lr_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrank_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_res_lr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_res_gbc_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrank_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_res_gbc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_res_rf_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrank_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_res_rf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_res_lr' is not defined"
     ]
    }
   ],
   "source": [
    "y_res_lr_rank = rank_pred(y_res_lr[:,1])\n",
    "y_res_gbc_rank = rank_pred(y_res_gbc[:,1])\n",
    "y_res_rf_rank = rank_pred(y_res_rf[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightedprobressrank(w1,w2,w3):\n",
    "    y_predict_ensemble =((w1/(w1+w2+w3) * y_res_lr_rank)  + (w2/(w1+w2+w3) * y_res_gbc_rank) + (w3/(w1+w2+w3) * y_res_rf_rank))\n",
    "    return y_predict_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_ensemble_rank = weightedprobressrank(maxi,maxj,maxk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5 - Resampling strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.791630005992\n",
      "0.790642335204\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours, CondensedNearestNeighbour\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import RandomOverSampler, smote\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Undersampling on logistic regression\n",
    "\n",
    "under_pipe=make_pipeline_imb(RandomUnderSampler(),LogisticRegression())\n",
    "scores=cross_val_score(under_pipe,X.drop(X.columns[klr],axis=1),y,cv=5,scoring='roc_auc')\n",
    "print (scores.mean())\n",
    "print (cross_val_score(LogisticRegression(),X.drop(X.columns[klr],axis=1),y,cv=5,scoring='roc_auc').mean())\n",
    "#0.791630005992\n",
    "#0.790642335204\n",
    "\n",
    "#Improvement of 0.001 in AUC\n",
    "#Used this model for one of the submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Undersampling on GBC\n",
    "under_pipe=make_pipeline_imb(RandomUnderSampler(),GradientBoostingClassifier())\n",
    "scores=cross_val_score(under_pipe,X,y,cv=2,scoring='roc_auc')\n",
    "print (scores.mean())\n",
    "print (cross_val_score(GradientBoostingClassifier(),X,y,cv=2,scoring='roc_auc').mean())\n",
    "#0.78762921968\n",
    "#0.793646912836\n",
    "#Performance dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Oversampling on Logistic regression\n",
    "over_pipe=make_pipeline_imb(RandomOverSampler(),LogisticRegression())\n",
    "scores=cross_val_score(over_pipe,X.drop(X.columns[klr],axis=1),y,cv=2,scoring='roc_auc')\n",
    "print (scores.mean())\n",
    "print (cross_val_score(LogisticRegression(),X.drop(X.columns[klr],axis=1),y,cv=2,scoring='roc_auc').mean())\n",
    "#0.791578810476\n",
    "#0.790642335204\n",
    "#Improvement of 0.001 in AUC\n",
    "#Used this model in ensemble for one of the submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Oversampling on GBC\n",
    "#over_pipe=make_pipeline_imb(RandomOverSampler(),GradientBoostingClassifier())\n",
    "#scores=cross_val_score(over_pipe,X,y,cv=2,scoring='roc_auc')\n",
    "#print scores.mean()\n",
    "#print cross_val_score(GradientBoostingClassifier(),X,y,cv=5,scoring='roc_auc').mean()\n",
    "#0.794911555413\n",
    "#0.796930884232\n",
    "#Performance dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using class weights while training the model\n",
    "print (cross_val_score(LogisticRegression(class_weight='balanced'),X.drop(X.columns[klr],axis=1),y,cv=5,scoring='roc_auc').mean())\n",
    "print (cross_val_score(LogisticRegression(),X.drop(X.columns[klr],axis=1),y,cv=5,scoring='roc_auc').mean())\n",
    "#Same results as oversampling\n",
    "print (cross_val_score(RandomForestClassifier(class_weight='balanced'),X,y,cv=2,scoring='roc_auc').mean())\n",
    "print (cross_val_score(RandomForestClassifier(),X,y,cv=2,scoring='roc_auc').mean())\n",
    "#Dropped for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Easy ensemble\n",
    "def resampled_ensemble(estimator,n=100):\n",
    "    estimators=[]\n",
    "    for i in range(n):\n",
    "        est=clone(estimator)\n",
    "        if hasattr(est,'random_state'):\n",
    "            random_state=i\n",
    "        pipe=make_pipeline_imb(RandomUnderSampler(random_state=i,replacement=True),est)\n",
    "        estimators.append((\"est_i\".format(i),pipe))\n",
    "    return VotingClassifier(estimators,voting='soft')\n",
    "\n",
    "resampled_logistic=resampled_ensemble(LogisticRegression(),20)\n",
    "scores=cross_val_score(resampled_logistic,X,y,cv=5,scoring='roc_auc')\n",
    "scores.mean()\n",
    "#Marginal improvement of 0.001 in AUC\n",
    "#Tried for different value of n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Edited Nearest Neighbor(commenting out fititng so travis doesn't timeout)\n",
    "enn_pipe=make_pipeline_imb(EditedNearestNeighbours(n_neighbors=10),LogisticRegression())\n",
    "#print (cross_val_score(enn_pipe,X,y,cv=5,scoring='roc_auc').mean())\n",
    "#no improvement\n",
    "#0.786976438259\n",
    "\n",
    "enn_pipe=make_pipeline_imb(EditedNearestNeighbours(n_neighbors=5),GradientBoostingClassifier())\n",
    "#print (cross_val_score(enn_pipe,X,y,cv=5,scoring='roc_auc').mean())\n",
    "#no improvement\n",
    "#0.795287038779\n",
    "\n",
    "#Grid searched neigbors. Best one did not give any improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Condensed nearest neigbors\n",
    "\n",
    "cnn_pipe=make_pipeline_imb(CondensedNearestNeighbour(n_neighbors=10),LogisticRegression())\n",
    "#print (cross_val_score(cnn_pipe,X,y,cv=5,scoring='roc_auc').mean())\n",
    "#Grid searched neigbors. Best one did not give any improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "#smote_pipe=make_pipeline_imb(SMOTE(),LogisticRegression())\n",
    "#print (cross_val_score(smote_pipe,X,y,cv=5,scoring='roc_auc').mean())\n",
    "#Grid searched neigbors. Best one did not give any improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "travistest = roc_auc_score(y_test,y_predict_ensemble[:,1])\n",
    "assert travistest > 0.79"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
